{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMg4bwv1wcsJHNXRFCH/ow4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/justanotheruser/AvitoCarSparePartsScraper/blob/main/Twitter_scrapper.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LKxPseM54EW7",
        "outputId": "712d2e06-6b82-4c48-e228-84cedcba3b49"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Archive:  twitter-scraper-selenium.zip\n",
            "   creating: ca/\n",
            "  inflating: ca/ca.crt               \n",
            "  inflating: ca/ca.key               \n",
            "   creating: twitter_scraper_selenium/\n",
            "  inflating: twitter_scraper_selenium/driver_initialization.py  \n",
            "  inflating: twitter_scraper_selenium/driver_utils.py  \n",
            "  inflating: twitter_scraper_selenium/element_finder.py  \n",
            "  inflating: twitter_scraper_selenium/keyword.py  \n",
            "  inflating: twitter_scraper_selenium/keyword_api.py  \n",
            "  inflating: twitter_scraper_selenium/profile.py  \n",
            "  inflating: twitter_scraper_selenium/profile_api.py  \n",
            "  inflating: twitter_scraper_selenium/profile_details.py  \n",
            "  inflating: twitter_scraper_selenium/requirements.txt  \n",
            "  inflating: twitter_scraper_selenium/scraping_utilities.py  \n",
            "  inflating: twitter_scraper_selenium/topic.py  \n",
            "  inflating: twitter_scraper_selenium/topic_api.py  \n",
            "  inflating: twitter_scraper_selenium/__init__.py  \n",
            "   creating: twitter_scraper_selenium/__pycache__/\n",
            "  inflating: twitter_scraper_selenium/__pycache__/driver_initialization.cpython-310.pyc  \n",
            "  inflating: twitter_scraper_selenium/__pycache__/driver_utils.cpython-310.pyc  \n",
            "  inflating: twitter_scraper_selenium/__pycache__/element_finder.cpython-310.pyc  \n",
            "  inflating: twitter_scraper_selenium/__pycache__/keyword.cpython-310.pyc  \n",
            "  inflating: twitter_scraper_selenium/__pycache__/keyword_api.cpython-310.pyc  \n",
            "  inflating: twitter_scraper_selenium/__pycache__/profile.cpython-310.pyc  \n",
            "  inflating: twitter_scraper_selenium/__pycache__/profile_api.cpython-310.pyc  \n",
            "  inflating: twitter_scraper_selenium/__pycache__/profile_details.cpython-310.pyc  \n",
            "  inflating: twitter_scraper_selenium/__pycache__/scraping_utilities.cpython-310.pyc  \n",
            "  inflating: twitter_scraper_selenium/__pycache__/topic.cpython-310.pyc  \n",
            "  inflating: twitter_scraper_selenium/__pycache__/topic_api.cpython-310.pyc  \n",
            "  inflating: twitter_scraper_selenium/__pycache__/__init__.cpython-310.pyc  \n",
            "  inflating: few_names.txt           \n",
            "  inflating: mutually_exclusive_option.py  \n",
            "  inflating: twitter_scrapper.py     \n"
          ]
        }
      ],
      "source": [
        "!unzip twitter-scraper-selenium.zip"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install click tqdm click-default-group openpyxl python-dateutil==2.8.2 selenium==4.7.0 selenium-wire==5.1.0 webdriver-manager==3.2.2 fake-headers==1.0.2 requests==2.27.1"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "XAtzpaL06MNx",
        "outputId": "b0322276-6fe1-4bf6-f7d9-ee541afe0a81"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (8.1.3)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (4.65.0)\n",
            "Collecting click-default-group\n",
            "  Downloading click-default-group-1.2.2.tar.gz (3.3 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: openpyxl in /usr/local/lib/python3.10/dist-packages (3.0.10)\n",
            "Requirement already satisfied: python-dateutil==2.8.2 in /usr/local/lib/python3.10/dist-packages (2.8.2)\n",
            "Collecting selenium==4.7.0\n",
            "  Downloading selenium-4.7.0-py3-none-any.whl (6.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.3/6.3 MB\u001b[0m \u001b[31m47.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting selenium-wire==5.1.0\n",
            "  Downloading selenium_wire-5.1.0-py3-none-any.whl (239 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m239.6/239.6 kB\u001b[0m \u001b[31m23.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting webdriver-manager==3.2.2\n",
            "  Downloading webdriver_manager-3.2.2-py2.py3-none-any.whl (16 kB)\n",
            "Collecting fake-headers==1.0.2\n",
            "  Downloading fake_headers-1.0.2-py3-none-any.whl (17 kB)\n",
            "Requirement already satisfied: requests==2.27.1 in /usr/local/lib/python3.10/dist-packages (2.27.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil==2.8.2) (1.16.0)\n",
            "Collecting trio~=0.17\n",
            "  Downloading trio-0.22.0-py3-none-any.whl (384 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m384.9/384.9 kB\u001b[0m \u001b[31m27.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: urllib3[socks]~=1.26 in /usr/local/lib/python3.10/dist-packages (from selenium==4.7.0) (1.26.15)\n",
            "Collecting trio-websocket~=0.9\n",
            "  Downloading trio_websocket-0.10.2-py3-none-any.whl (17 kB)\n",
            "Requirement already satisfied: certifi>=2021.10.8 in /usr/local/lib/python3.10/dist-packages (from selenium==4.7.0) (2022.12.7)\n",
            "Requirement already satisfied: pyparsing>=2.4.2 in /usr/local/lib/python3.10/dist-packages (from selenium-wire==5.1.0) (3.0.9)\n",
            "Collecting brotli>=1.0.9\n",
            "  Downloading Brotli-1.0.9-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (2.7 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.7/2.7 MB\u001b[0m \u001b[31m72.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting h2>=4.0\n",
            "  Downloading h2-4.1.0-py3-none-any.whl (57 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m57.5/57.5 kB\u001b[0m \u001b[31m7.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting zstandard>=0.14.1\n",
            "  Downloading zstandard-0.21.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.7 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.7/2.7 MB\u001b[0m \u001b[31m84.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting hyperframe>=6.0\n",
            "  Downloading hyperframe-6.0.1-py3-none-any.whl (12 kB)\n",
            "Collecting blinker>=1.4\n",
            "  Downloading blinker-1.6.2-py3-none-any.whl (13 kB)\n",
            "Requirement already satisfied: pysocks>=1.7.1 in /usr/local/lib/python3.10/dist-packages (from selenium-wire==5.1.0) (1.7.1)\n",
            "Collecting wsproto>=0.14\n",
            "  Downloading wsproto-1.2.0-py3-none-any.whl (24 kB)\n",
            "Collecting kaitaistruct>=0.7\n",
            "  Downloading kaitaistruct-0.10-py2.py3-none-any.whl (7.0 kB)\n",
            "Requirement already satisfied: pyasn1>=0.3.1 in /usr/local/lib/python3.10/dist-packages (from selenium-wire==5.1.0) (0.5.0)\n",
            "Collecting pyOpenSSL>=22.0.0\n",
            "  Downloading pyOpenSSL-23.1.1-py3-none-any.whl (57 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m57.9/57.9 kB\u001b[0m \u001b[31m7.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting configparser\n",
            "  Downloading configparser-5.3.0-py3-none-any.whl (19 kB)\n",
            "Collecting crayons\n",
            "  Downloading crayons-0.4.0-py2.py3-none-any.whl (4.6 kB)\n",
            "Collecting bs4\n",
            "  Downloading bs4-0.0.1.tar.gz (1.1 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: html5lib in /usr/local/lib/python3.10/dist-packages (from fake-headers==1.0.2) (1.1)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests==2.27.1) (2.0.12)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests==2.27.1) (3.4)\n",
            "Requirement already satisfied: et-xmlfile in /usr/local/lib/python3.10/dist-packages (from openpyxl) (1.1.0)\n",
            "Collecting hpack<5,>=4.0\n",
            "  Downloading hpack-4.0.0-py3-none-any.whl (32 kB)\n",
            "Requirement already satisfied: cryptography<41,>=38.0.0 in /usr/local/lib/python3.10/dist-packages (from pyOpenSSL>=22.0.0->selenium-wire==5.1.0) (40.0.2)\n",
            "Collecting outcome\n",
            "  Downloading outcome-1.2.0-py2.py3-none-any.whl (9.7 kB)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from trio~=0.17->selenium==4.7.0) (1.3.0)\n",
            "Collecting async-generator>=1.9\n",
            "  Downloading async_generator-1.10-py3-none-any.whl (18 kB)\n",
            "Requirement already satisfied: sortedcontainers in /usr/local/lib/python3.10/dist-packages (from trio~=0.17->selenium==4.7.0) (2.4.0)\n",
            "Requirement already satisfied: exceptiongroup>=1.0.0rc9 in /usr/local/lib/python3.10/dist-packages (from trio~=0.17->selenium==4.7.0) (1.1.1)\n",
            "Requirement already satisfied: attrs>=19.2.0 in /usr/local/lib/python3.10/dist-packages (from trio~=0.17->selenium==4.7.0) (23.1.0)\n",
            "Collecting h11<1,>=0.9.0\n",
            "  Downloading h11-0.14.0-py3-none-any.whl (58 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.3/58.3 kB\u001b[0m \u001b[31m6.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.10/dist-packages (from bs4->fake-headers==1.0.2) (4.11.2)\n",
            "Collecting colorama\n",
            "  Downloading colorama-0.4.6-py2.py3-none-any.whl (25 kB)\n",
            "Requirement already satisfied: webencodings in /usr/local/lib/python3.10/dist-packages (from html5lib->fake-headers==1.0.2) (0.5.1)\n",
            "Requirement already satisfied: cffi>=1.12 in /usr/local/lib/python3.10/dist-packages (from cryptography<41,>=38.0.0->pyOpenSSL>=22.0.0->selenium-wire==5.1.0) (1.15.1)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.10/dist-packages (from beautifulsoup4->bs4->fake-headers==1.0.2) (2.4.1)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.10/dist-packages (from cffi>=1.12->cryptography<41,>=38.0.0->pyOpenSSL>=22.0.0->selenium-wire==5.1.0) (2.21)\n",
            "Building wheels for collected packages: click-default-group, bs4\n",
            "  Building wheel for click-default-group (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for click-default-group: filename=click_default_group-1.2.2-py3-none-any.whl size=3383 sha256=b1ea6fdcbd4ccb75f7785d8d8bd07309aeffc0f021053d541e55fbb27f341836\n",
            "  Stored in directory: /root/.cache/pip/wheels/2b/9c/67/f0b289bc6f573ea3269695a1b8f63846147e0e2f7140347181\n",
            "  Building wheel for bs4 (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for bs4: filename=bs4-0.0.1-py3-none-any.whl size=1270 sha256=57953c2b262bc111f5fd0e39e7e2e77af5b0c605f878e6b11526ff88c09466bb\n",
            "  Stored in directory: /root/.cache/pip/wheels/25/42/45/b773edc52acb16cd2db4cf1a0b47117e2f69bb4eb300ed0e70\n",
            "Successfully built click-default-group bs4\n",
            "Installing collected packages: brotli, zstandard, outcome, kaitaistruct, hyperframe, hpack, h11, configparser, colorama, click-default-group, blinker, async-generator, wsproto, trio, h2, crayons, bs4, webdriver-manager, trio-websocket, pyOpenSSL, fake-headers, selenium, selenium-wire\n",
            "Successfully installed async-generator-1.10 blinker-1.6.2 brotli-1.0.9 bs4-0.0.1 click-default-group-1.2.2 colorama-0.4.6 configparser-5.3.0 crayons-0.4.0 fake-headers-1.0.2 h11-0.14.0 h2-4.1.0 hpack-4.0.0 hyperframe-6.0.1 kaitaistruct-0.10 outcome-1.2.0 pyOpenSSL-23.1.1 selenium-4.7.0 selenium-wire-5.1.0 trio-0.22.0 trio-websocket-0.10.2 webdriver-manager-3.2.2 wsproto-1.2.0 zstandard-0.21.0\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "configparser"
                ]
              }
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import re\n",
        "import subprocess\n",
        "import requests\n",
        "\n",
        "# The deb files we need to install\n",
        "deb_files_startstwith = [\n",
        "    \"chromium-codecs-ffmpeg-extra_\",\n",
        "    \"chromium-codecs-ffmpeg_\",\n",
        "    \"chromium-browser_\",\n",
        "    \"chromium-chromedriver_\"\n",
        "]\n",
        "\n",
        "def get_latest_version() -> str:\n",
        "    # A request to security.ubuntu.com for getting latest version of chromium-browser\n",
        "    # e.g. \"112.0.5615.49-0ubuntu0.18.04.1_amd64.deb\"\n",
        "    url = \"http://security.ubuntu.com/ubuntu/pool/universe/c/chromium-browser/\"\n",
        "    r = requests.get(url)\n",
        "    if r.status_code != 200:\n",
        "        raise Exception(\"status_code code not 200!\")\n",
        "    text = r.text\n",
        "\n",
        "    # Find latest version\n",
        "    pattern = '<a\\shref=\"chromium\\-browser_([^\"]+.ubuntu0\\.18\\.04\\.1_amd64\\.deb)'\n",
        "    latest_version_search = re.search(pattern, text)\n",
        "    if latest_version_search:\n",
        "        latest_version = latest_version_search.group(1)\n",
        "    else:\n",
        "        raise Exception(\"Can not find latest version!\")\n",
        "    return latest_version\n",
        "\n",
        "def download(latest_version: str, quiet: bool):\n",
        "    deb_files = []\n",
        "    for deb_file in deb_files_startstwith:\n",
        "        deb_files.append(deb_file + latest_version)\n",
        "\n",
        "    for deb_file in deb_files:\n",
        "        url = f\"http://security.ubuntu.com/ubuntu/pool/universe/c/chromium-browser/{deb_file}\"\n",
        "\n",
        "        # Download deb file\n",
        "        if quiet:\n",
        "            command = f\"wget -q -O /content/{deb_file} {url}\"\n",
        "        else:\n",
        "            command = f\"wget -O /content/{deb_file} {url}\"\n",
        "        print(f\"Downloading: {deb_file}\")\n",
        "        # os.system(command)\n",
        "        !$command\n",
        "\n",
        "        # Install deb file\n",
        "        if quiet:\n",
        "            command = f\"apt-get install /content/{deb_file} >> apt.log\"\n",
        "        else:\n",
        "            command = f\"apt-get install /content/{deb_file}\"\n",
        "        print(f\"Installing: {deb_file}\\n\")\n",
        "        # os.system(command)\n",
        "        !$command\n",
        "\n",
        "        # Delete deb file from disk\n",
        "        os.remove(f\"/content/{deb_file}\")\n",
        "\n",
        "def check_chromium_installation():\n",
        "    try:\n",
        "        subprocess.call([\"chromium-browser\"])\n",
        "        print(\"Chromium installation successfull.\")\n",
        "    except FileNotFoundError:\n",
        "        print(\"Chromium Installation Failed!\")\n",
        "\n",
        "def install_selenium_package(quiet: bool):\n",
        "    if quiet:\n",
        "        !pip install selenium -qq >> pip.log\n",
        "    else:\n",
        "        !pip install selenium\n",
        "\n",
        "def main(quiet: bool):\n",
        "    # Get the latest version of chromium-browser for ubuntu 18.04\n",
        "    latest_version = get_latest_version()\n",
        "    # Download and install chromium-browser for ubuntu 20.04\n",
        "    download(latest_version, quiet)\n",
        "    # Check if installation succesfull\n",
        "    check_chromium_installation()\n",
        "    # Finally install selenium package\n",
        "    install_selenium_package(quiet)\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    quiet = True # verboseness of wget and apt\n",
        "    main(quiet)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ec_s2Uqw7QqI",
        "outputId": "1d0b80ff-0a1d-4c50-e5a9-6409c2cb12e0"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading: chromium-codecs-ffmpeg-extra_112.0.5615.49-0ubuntu0.18.04.1_amd64.deb\n",
            "Installing: chromium-codecs-ffmpeg-extra_112.0.5615.49-0ubuntu0.18.04.1_amd64.deb\n",
            "\n",
            "Downloading: chromium-codecs-ffmpeg_112.0.5615.49-0ubuntu0.18.04.1_amd64.deb\n",
            "Installing: chromium-codecs-ffmpeg_112.0.5615.49-0ubuntu0.18.04.1_amd64.deb\n",
            "\n",
            "Downloading: chromium-browser_112.0.5615.49-0ubuntu0.18.04.1_amd64.deb\n",
            "Installing: chromium-browser_112.0.5615.49-0ubuntu0.18.04.1_amd64.deb\n",
            "\n",
            "Downloading: chromium-chromedriver_112.0.5615.49-0ubuntu0.18.04.1_amd64.deb\n",
            "Installing: chromium-chromedriver_112.0.5615.49-0ubuntu0.18.04.1_amd64.deb\n",
            "\n",
            "Chromium installation successfull.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python twitter_scrapper.py -i few_more_names.txt -o tweets.xlsx --last-hours 24 --threads 2"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EtLyOajt5onX",
        "outputId": "e3e4c66b-565a-4b55-96dd-ec7cd007e3ad"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Собираем твиты\n",
            "  0% 0/7 [00:00<?, ?it/s]\n",
            "  0% 0/7 [00:00<?, ?it/s]\u001b[A\n",
            " 14% 1/7 [00:50<05:04, 50.78s/it]\n",
            " 29% 2/7 [01:10<02:41, 32.24s/it]"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "gp2pIM9UA0pf"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}